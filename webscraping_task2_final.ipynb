{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Web Scraping Task 2 : Using Selenium/BS4 to Extract Horse Race Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Background** ###\n",
    " This notebook provides a step by step guide to to web scraping HTML content. We will utilize both Selenium and BeautifulSoup (BS4) to automate the process of navigating websites and handling dynamic JavaScript content. \n",
    " <br>\n",
    " \n",
    " In this example, weâ€™ll demonstrate how to navigate www.swiftbet.com.au chose one of tomorrows gallops races at random and scrape horse and odds data\n",
    "\n",
    "### **Step by Step Guide** ###\n",
    "The steps outlined below will guide you through the entire process:\n",
    "<br>\n",
    "\n",
    "1) **Import Libraries :** Importing the relevant libraries, and adding the relevant settings for our selenium driver. Some may require pip installs. \n",
    "\n",
    "2) **Initialise Selenium :** Load the selenium driver and navigate to todays racing page on SwiftBet.\n",
    "\n",
    "3) **Navigate to Tomorrows Races :** Use selenium to navigate to tomorrows races.\n",
    "\n",
    "4) **Scrape Element Data and Chose Race:** Scrape all of the race elements and chose a race at random and navigste to its page.\n",
    "\n",
    "5) **Scrape HTML for Race Data :** Scrape the relevant data for horse names and odds.\n",
    "\n",
    "6) **Construct DataFrame :** Construct our DataFrame.\n",
    "\n",
    "7) **Make Title for DataFrame :** Format a title for our file name.\n",
    "\n",
    "8) **Export DataFrame :** Export our DataFrame as .CSV file.\n",
    "<br>\n",
    "\n",
    "By the end of this notebook, you will have a clear understanding of how to scrape and process web data, even from complex sites with dynamic content.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries, some of which may require pip installs\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd \n",
    "import random\n",
    "from datetime import datetime, timedelta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising selenium and adding optional settings\n",
    "options = Options()\n",
    "#options.add_argument(\"--headless\") #Ran without headless mode as it wasn't loading elements properly\n",
    "options.add_argument(\"--disable-gpu\")  # Disables GPU hardware acceleration\n",
    "options.add_argument(\"--no-sandbox\")   # Bypasses OS security model\n",
    "options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "driver = webdriver.Chrome(options = options) # Using Chrome as web driver \n",
    "site =  \"https://www.swiftbet.com.au\" # Swiftbets URL\n",
    "driver.get(site) # Accessing site with selenium\n",
    "driver.implicitly_wait(30) # Waiting for JavaScript elements to load/render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on the link to the racing page \n",
    "racing_button = driver.find_element(By.XPATH, \"//div[contains(text(), 'Racing')]\")\n",
    "racing_button.click()\n",
    "driver.implicitly_wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on the link to tomorrows races in AU/NZ\n",
    "tomorrow_button = driver.find_element(By.CSS_SELECTOR, \"button[data-fs-title='page:racing-tab:tomorrow-header_bar']\")\n",
    "tomorrow_button.click()\n",
    "driver.implicitly_wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# Extracting the elements from tomorrows gallops races\n",
    "race_elements_tomorrow = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/racing/gallops/']\")\n",
    "\n",
    "# Checking the length of race elements \n",
    "print(len(race_elements_tomorrow))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing a random race \n",
    "if not race_elements_tomorrow:\n",
    "    print(\"No race elements found.\")\n",
    "else:\n",
    "        # Randomly select a race\n",
    "    random_race = random.choice(race_elements_tomorrow)\n",
    "        \n",
    "        # Click on the randomly selected race\n",
    "    random_race.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise BeautifulSoup with the page source\n",
    "current_url = driver.current_url\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the elements which encase the information of horses in the randomly selected race\n",
    "horse_items = soup.find_all('li', class_='name styles egik0gw0 css-1c8uam-ListItem-ListItem-ListItem-RaceSelectionsListItem-RaceSelectionsListItem-RaceSelectionsListItem-RaceSelectionsListItem e1ad0cjx0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Star Magnum', 'Ocean Emperor', 'Mathematics', 'Pompeii Empire']\n"
     ]
    }
   ],
   "source": [
    "# Extracting the horses names \n",
    "\n",
    "# Initialise list\n",
    "horses_names = []\n",
    "\n",
    "# Loop through elements to extract the horses names\n",
    "for item in horse_items:\n",
    "    # Find the div containing the horse name\n",
    "    horse_name_div = item.find('div', class_='e3trgs57 css-1bpf5z2-Text-Text-RaceSelectionDetails-RaceSelectionsDetails__Name-RaceSelectionDetails-RaceSelectionDetails ea6hjv30')\n",
    "    \n",
    "    if horse_name_div:\n",
    "        # Get the full text from the div\n",
    "        full_text = horse_name_div.get_text(strip=True)\n",
    "        \n",
    "        # Split by whitespace and remove the first element (the number and dot)\n",
    "        name_parts = full_text.split()\n",
    "        horse_name = ' '.join(name_parts[1:])\n",
    "        \n",
    "        # Remove the trailing number in parentheses if present\n",
    "        horse_name = horse_name.split('(')[0].strip()\n",
    "        \n",
    "        # Append horse name to list\n",
    "        horses_names.append(horse_name)\n",
    "\n",
    "# Checking the result \n",
    "print(horses_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MID', 'MID', 'MID', 'MID']\n"
     ]
    }
   ],
   "source": [
    "# Extracting the selection of odds for each horse \n",
    "\n",
    "# Initialise list\n",
    "odds_list = []\n",
    "\n",
    "# Loop through the elements which contain the horse information to extract the odds data.\n",
    "for item in horse_items:\n",
    "    # Find all span elements containing the odds\n",
    "    odds_spans = item.find_all('span', class_='eatknsg1 css-fvda5w-Text-Text-BettingAdd-styled-BettingAdd__Single-BettingAdd-styled ea6hjv30')\n",
    "    \n",
    "    if odds_spans:\n",
    "        # Extract text from each odds span and combine them if there are multiple\n",
    "        odds = ' / '.join([span.get_text(strip=True) for span in odds_spans])\n",
    "        odds_list.append(odds)\n",
    "    else:\n",
    "        # In case no odds are found\n",
    "        odds_list.append(\"N/A\")  \n",
    "\n",
    "# Checking the result \n",
    "print(odds_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['MID'], ['MID'], ['MID'], ['MID']]\n"
     ]
    }
   ],
   "source": [
    "# Formatting the odds list into a list of lists, using '/' as a delimiter\n",
    "\n",
    "# Initialising list \n",
    "complete_odds_list = [] \n",
    "\n",
    "# Looping through to seperate the different types of odds for each horse\n",
    "for odd in odds_list : \n",
    "    odd_array = odd.split('/')\n",
    "    complete_odds_list.append(odd_array)\n",
    "\n",
    "# Checking the result \n",
    "print(complete_odds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MID (W)']\n"
     ]
    }
   ],
   "source": [
    "# Extracting the names of the different types of odds\n",
    "\n",
    "# Find div which contain the odds types\n",
    "odds_titles_div = soup.find('div', class_='en9z9v51 css-sfxk7f-Text-Text-RaceSelectionsList-RaceSelectionsList__HeaderRow-RaceSelectionsList ea6hjv30')\n",
    "\n",
    "# Initialising list \n",
    "odds_titles = []\n",
    "\n",
    "# Find all divs within the parent div that contain the odds types\n",
    "if odds_titles_div:\n",
    "    titles = odds_titles_div.find_all('div', class_='css-101kdtv-RaceSelectionsList-RaceSelectionsList__HeaderCell-RaceSelectionsList-RaceSelectionsList en9z9v52')\n",
    "    \n",
    "    for title in titles:\n",
    "        odds_titles.append(title.get_text(strip=True))\n",
    "\n",
    "# Checking the result\n",
    "print(odds_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitting the selenium driver \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lists are same length\n"
     ]
    }
   ],
   "source": [
    "# Checking if all strings are the same length \n",
    "if len(horses_names) == len(odds_list) : \n",
    "    print('All lists are same length')\n",
    "else : \n",
    "    print('List lengths are not the same length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Horse Name\n",
      "0     Star Magnum\n",
      "1   Ocean Emperor\n",
      "2     Mathematics\n",
      "3  Pompeii Empire\n"
     ]
    }
   ],
   "source": [
    "# Constructing the DataFrame \n",
    "df_performed_bets = pd.DataFrame({'Horse Name' : horses_names})\n",
    "print(df_performed_bets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Horse Name MID (W)\n",
      "0     Star Magnum     MID\n",
      "1   Ocean Emperor     MID\n",
      "2     Mathematics     MID\n",
      "3  Pompeii Empire     MID\n"
     ]
    }
   ],
   "source": [
    "# Making the indexes match the odds elements and forming the dataframe\n",
    "for i, title in enumerate(odds_titles) : \n",
    "    odds = [odds[i] for odds in complete_odds_list]\n",
    "    df_performed_bets[title] = odds \n",
    "\n",
    "print(df_performed_bets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting and forming a title to use in the file name \n",
    "title = soup.title.string.split()\n",
    "full_title = f'{title[0]}_{title[1]}_{title[2]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting todays date, formatting the file name and exporting to .csv \n",
    "tomorrow = datetime.now().date() + timedelta(days=1)\n",
    "file_name = f'{full_title}_{tomorrow}'\n",
    "df_performed_bets.to_csv(file_name, index = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
